{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from analyzer import data_cleaner\n",
    "from analyzer.data_transformation import TfidfDataTransformer, BagOfWordsTransformer, DataTransformer\n",
    "\n",
    "from imblearn.under_sampling import TomekLinks,RandomUnderSampler, CondensedNearestNeighbour,EditedNearestNeighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "def load_and_clean_data(filepath, vectorizer_output='models/vectorizer.sav', **kwargs) -> (pd.DataFrame, DataTransformer):\n",
    "    # Load data\n",
    "    df = pd.read_csv(filepath, **kwargs)\n",
    "    # Clean data\n",
    "        # Remove @ mentions\n",
    "    df['clean_text'] = np.vectorize(data_cleaner.clean_mentions)(df['text'])\n",
    "        # Remove non alfabet chars\n",
    "    df['clean_text'] = df['clean_text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "        # Remove short words\n",
    "    df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "    # Transform\n",
    "    tr = TfidfDataTransformer()\n",
    "    # Stemming\n",
    "    df['clean_text'] = tr.stemming(df['clean_text'])\n",
    "\n",
    "    df_tfidf = tr.transform(df['clean_text'])\n",
    "    pickle.dump(tr.vectorizer, open(vectorizer_output, 'wb'))\n",
    "\n",
    "\n",
    "    return df, df_tfidf, tr\n",
    "\n",
    "def balance_data(X, y, balancer = RandomUnderSampler(sampling_strategy='not minority',random_state=1337)) -> pd.DataFrame:\n",
    "    X_balanced, y_balanced = balancer.fit_resample(X, y)\n",
    "    return X_balanced, y_balanced\n",
    "\n",
    "\n",
    "\n",
    "def fit_model(X, y, model_type, model_output='../models/model.sav', **kwargs):\n",
    "    model = model_type(**kwargs)\n",
    "    model.fit(X,y)\n",
    "    if model_output is not None:\n",
    "        pickle.dump(model, open(model_output, 'wb'))\n",
    "    return model\n",
    "\n",
    "proba_models = set(['LogisticRegression'])\n",
    "def predict(model, data):\n",
    "    model_name = type(model).__name__\n",
    "    if model_name in proba_models:\n",
    "        predictions = model.predict_proba(data)\n",
    "    else:\n",
    "        predictions = model.predict(data)\n",
    "    return predictions\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df, df_tfidf, tr = load_and_clean_data('data/train.csv')\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_tfidf, df['output'],test_size=0.3,random_state=42)\n",
    "\n",
    "X_train_balanced, y_train_balanced = balance_data(X_train, y_train)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
